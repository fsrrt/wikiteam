#summary Help us to archive a gallizion of wikis
#labels Featured
#sidebar Sidebar
Here, we coordinate us to download all *non WikiFarms* wikis.

We start with a [http://www.cs.brown.edu/~pavlo/mediawiki/ list from Andrew Pavlo], which is [http://code.google.com/p/wikiteam/source/browse/trunk/listsofwikis/mediawikis_pavlo.csv mirrored here]. After discarding dead wikis, we have about [http://code.google.com/p/wikiteam/source/browse/trunk/listsofwikis/mediawikis_pavlo.alive.filtered.txt 7,400+ alive wikis].

== Requirements ==
You need GNU/Linux, Python and p7zip-full (sudo apt-get install p7zip-full).

== How to join the effort? ==

Download a list (every list has 100 wikis):

  * Choose one from [http://code.google.com/p/wikiteam/source/browse/trunk#trunk%2Fbatchdownload%2Flists 000 to 073]

And use the following scripts to backup the wikis:

  * [http://wikiteam.googlecode.com/svn/trunk/batchdownload/launcher.py launcher.py]
  * [http://wikiteam.googlecode.com/svn/trunk/dumpgenerator.py dumpgenerator.py]

After downloading a list and both scripts in the same directory, you can do: *python launcher.py mylist.txt*

It will backup every wiki and generate two 7z files for each one: _domain-date-history.xml.7z_ (just wikitext) and _domain-date-wikidump.7z_ (wikitext and images/ directory).

See also the NewTutorial page for details on how the scripts work.

*Note*: we recommend to split every 100 wikis list into 10 lists of 10. You can do that with the {{{split}}} command like this: {{{split -l10 list000 list000-}}}

=== Volunteers table ===

Lists claimed by users. Notify us when you start downloading a list of wikis. If you can't edit this page, email us in [https://groups.google.com/group/wikiteam-discuss our mailing list] (you have to join).

|| *List* || *Member* || *Status* || *Notes * ||
|| 000 || emijrp || Downloading || Downloaded: X. Incomplete: X. Errors: X. ||
|| 001 || ScottDB || Downloading ||... ||
|| 002 || underscor || Downloading || ... ||
|| 003 || Nemo || Downloading || Several big wikis here, including citywiki.ugr.es which seems to have about 100 GB of images (underscor will download the images). ||
|| 004 || ianmcorvidae || Downloading || ... ||
|| 005 || Nemo || _Downloaded_ || [http://p.defau.lt/?b_5gXJxVTPPzppgd7jxfrg Final check] ||
|| 006 || Nemo || Downloading || [http://p.defau.lt/?xFZdHVoVpJBhI5fA5icN3g Final check] ||
|| 007 || Nemo || _Downloaded_ || [http://p.defau.lt/?3qpqOZdAwinhcBFqCAg4vg Final check] ||
|| 008 || Nemo || _Downloaded_ || [http://p.defau.lt/?mS38BbpNQteTQZa8AI3mWQ Final check] ||
|| 009 || Nemo || _Downloaded_ || [http://p.defau.lt/?N4iuP5BFsmNjxf1wJ6GLDw Final check] ||
|| 010 || Nemo || _Downloaded_ || [http://p.defau.lt/?cuYNGuhwREQeDJZV0wlu4A Final check] (katlas.math.toronto.edu has 1.6 million pages, doing separately: end expected for mid May) ||
|| 011 || mutoso || _Downloaded_ || [http://p.defau.lt/?1_xFsDt6XdQMf_b0Ln9Kpg Final check] ||
|| 012 || Nemo || _Downloaded_ || [http://p.defau.lt/?c_BiYqgcaqw3WHpIsYiZYg Final check] ||
|| 013 || Nemo || Downloading || ... ||
|| 014 || Nemo || _Downloaded_ || [http://p.defau.lt/?_23I5WxxA1Nl420d7e2w6g Final check] ||
|| 015 || Nemo || _Downloaded_ || [http://p.defau.lt/?KwIjaL3YnDFaLZAxguSz5g Final check] ||
|| 016 || Nemo || _Downloaded_ || [http://p.defau.lt/?pivzqD3LC9vLC0v1nIhm9w Final check] ||
|| 017 || Nemo || _Downloaded_ || [http://p.defau.lt/?pacTBWaiBfOGWW00Qdzaew Final check] ||
|| 018 || Nemo || Downloading || ||
|| 019 || Nemo || Downloading || ||
|| 020 || mutoso || || ... ||
|| 021 || Nemo || Downloading || ||
|| 022 || Nemo || Downloading || ||
|| 023 || Nemo || Downloading || ||
|| 024 || Nemo || Downloading || ||
|| 025 || Nemo || Downloading || ||
|| 026 || Nemo || Downloading || ||
|| 027 || Nemo || Downloading || ||
|| 028 || Nemo || Downloading || ||
|| 029 || Nemo || Downloading || ||
|| 030 || Nemo || Downloading || ||
|| 031 || Nemo || Downloading || ||
|| 032 || ... || || ... ||
|| 033 || ... || || ... ||
|| 034 || ... || || ... ||
|| 035 || ... || || ... ||
|| 036 || ... || || ... ||
|| 037 || ... || || ... ||
|| 038 || ... || || ... ||
|| 039 || ... || || ... ||

== Where/How to upload the dumps? ==

We will upload the dumps to the [http://archive.org/details/wikiteam WikiTeam Collection] at Internet Archive. Please, wait for further instructions.